Forskare: Vi vet för lite om det som hotar vår existens
Maria Gunther

Apokalypsen kan se ut på många sätt. Kärnvapenkrig, som sprider radioaktivt nedfall över planeten och leder till åratal av vinter. Klimatförändringar som gör större delen av jorden obeboelig. Pandemier – världsomfattande epidemier, orsakade av nya naturliga smittoämnen eller av konstgjorda virus. Artificiell intelligens som blir smartare än vi och inte längre ser någon användning för människan. Asteroidnedslag eller stora vulkanutbrott. En global kollaps av ekonomin eller av jordbruket så att det inte längre går att producera den mat vi behöver för att överleva.

Hoten mot mänsklighetens existens har kanske aldrig varit större. Ändå saknas det forskning på området.

– Det är helt absurt att detta är så underutforskat. Det finns fler vetenskapliga publikationer om dyngbaggar än om existentiell risk, säger Anders Sandberg på Future of Humanity Institute vid universitetet i Oxford.

Under september och oktober är han vetenskaplig ledare för forskningsprogrammet ”Existential risk to humanity” på Chalmers och Göteborgs universitet. Värd och initiativtagare är Olle Häggström, professor i matematisk statistik på Chalmers.

– Ur mitt perspektiv som människa är mänsklighetens överlevnad en väldigt viktig fråga. Vi har en bred diskussion om klimatförändringarna och kärnvapenhotet, men det saknas om de andra, kanske lika allvarliga hoten, säger Olle Häggström.

De största akuta hoten är de vi själva har skapat.

– Tittar vi på det som är akut för att vi ska överleva de närmaste 100 åren kan vi nästan försumma asteroidfaran. Men om mänskligheten ska fortsätta att blomstra i tusentals eller miljoner år, måste vi fixa det här med asteroiderna. För förr eller senare kommer det en, säger Olle Häggström.

Det krävs inte längre stora ekonomiska tillgångar för att skapa nya hot.

– Kärnvapen är fortfarande efter 70 år ett tiotal nationers exklusiva egendom. Det finns inte enskilda personer eller terroristgrupper med tillgång till kärnvapen, vad vi vet, eftersom teknologin kräver storindustriella resurser som är svåra för små grupper att klara. Men en del av de nya farliga teknologierna, som bioteknik, syntetiska virus och liknande är svårare att hålla inom ett begränsat antal aktörer, säger Olle Häggström.

– Vi har haft pandemier som har dödat tiotals och till och med hundratals miljoner människor. Det kan hända naturligt. Men med lite hjälp vet vi att människor kan göra saker bra mycket värre, eftersom biotekniken har blivit så mycket bättre, säger Anders Sandberg.

Båda två har framför allt ägnat sig åt hoten från avancerad artificiell intelligens.

– Om den artificiella intelligensen blir riktigt smart, kan vi hantera den, och hur farlig är den? I nuläget har ingen någon riktigt bra idé om hur vi ska göra superintelligens säker. Det ligger en bra bit in i framtiden, men givet hur svår frågan är bör man börja fundera på den tidigt, säger Anders Sandberg.

– Den dagen vi inte längre är smartast på planeten kan vi inte räkna med att automatiskt behålla kontrollen. Risken är stor att vi hamnar i händerna på de här maskinerna. Om de vill oss väl kan det bli ganska bra. Men har vi inte sett till att ordna det tillräckligt noga kan det gå illa, säger Olle Häggström.

Det blir också ett filosofiskt problem.

– Än har filosoferna inte på ett tillfredställande sätt lyckats definiera vad det är att vilja någon väl. Och nu håller det på att bli en teknisk fråga som vi helst bör lösa innan någon tillräckligt smart ingenjör på Google eller någon annanstans löser problemet med artificiell intelligens, säger Anders Sandberg.

Klassiska abstrakta filosofiska och etiska dilemman har redan nu blivit praktiska tekniska problem. Ett exempel är det så kallade spårvagnsproblemet, som i en variant handlar om ifall det är etiskt riktigt att låta är en herrelös skenande spårvagn döda en person på ett spår för att hindra att den kör ihjäl fem personer på ett annat.

– Nu är det något som konstruktörer av förarlösa bilar behöver ta ställning till. Hur ska bilen göra i en sådan situation? Det vi pratar om är en gigantisk uppskalning av den sortens problematik, säger Olle Häggström.

Ett annat problem är att vår moderna teknologiska civilisation är mycket bräcklig.

– En av de mera troliga existentiella riskerna är att den globala infrastrukturen fallerar. Om ekonomin kollapsar kan vi inte transportera olja, och så har vi ingen energi, och ingen mat, säger Anders Sandberg.

Men kan vår art verkligen finnas kvar i tusentals eller miljontals år?

– Om vi var en helt vanlig slumpmässig däggdjursart så kan man räkna med att vi kan överleva i ungefär en miljon år. Men vi är inte en särskilt normal art. Det är inte orimligt att anta en anpassningsbar mänsklighet kan leva betydligt längre, säger Anders Sandberg.

Då menar han även nya arter vi kan utvecklas till, kanske genom att vi med teknik förändrar och förbättrar oss själva.

– Om vi kan undvika de här riskerna har vi en potentiellt enormt stor och enormt lång framtid, säger han.

Det är en anledning till att det är viktigt att undersöka och förebygga de existentiella riskerna.

– Även om vi räknar bara i människoliv, och inte i upptäckter, eller filosofiska insikter, eller musik, eller kärlek, eller vad det är för valuta värde bör räknas i, så är det potentiella värdet i framtiden enormt stort. Om vi går under nu, går allt det förlorat. Vi har ett ansvar mot kommande generationer att se till at de blir till, säger Anders Sandberg.
